{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e52355-ef21-4e35-aee8-b3c15b2469d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23779d06-066d-4f88-9351-0da171f2ac7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02d59d02-a029-4f6a-a8e2-a3eebfed307f",
   "metadata": {},
   "source": [
    "### This notebook is for Sina to run the 3D segmentation and extract the centriod of the neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc4f39f-4fc0-4800-948b-b2ff1bfd1799",
   "metadata": {},
   "source": [
    "- install tensorflow and stardist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90e12dfe-be20-4b87-92b5-b1e3d0d6d569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-28 18:21:52.490958: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-28 18:22:01.326770: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /shared/centos7/cuda/11.8/lib64:/shared/centos7/nodejs/14.15.4/lib\n",
      "2025-01-28 18:22:01.327427: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /shared/centos7/cuda/11.8/lib64:/shared/centos7/nodejs/14.15.4/lib\n",
      "2025-01-28 18:22:01.327504: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.11.0\n",
      "StarDist version: 0.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from stardist import __version__ as stardist_version\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"StarDist version:\", stardist_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882b1409-1037-4265-800e-ca3ae1d7ec10",
   "metadata": {},
   "source": [
    "- load the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0cbc99-b741-4554-9d8b-191ba5523838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Tesla V100-PCIE-32GB\n",
      "True\n",
      "2.11.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from func_seg import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb470fa-9972-4f8f-93e8-b30f6129aca1",
   "metadata": {},
   "source": [
    "- load stardist 3D and model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0858bfd5-4d81-42a7-beac-b723e2d4bb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_gpu:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "base_model.py (203): output path for model already exists, files may be overwritten: /work/venkatachalamlab/Hang/00Neuron_tracking_version2/01version/Matching_anchor/Sina_seg/models/stardist\n",
      "2025-01-28 18:22:46.424356: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-28 18:22:46.785624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31141 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:81:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.707933, nms_thresh=0.3.\n",
      "There are 4 registered models for 'StarDist2D':\n",
      "\n",
      "Name                  Alias(es)\n",
      "────                  ─────────\n",
      "'2D_versatile_fluo'   'Versatile (fluorescent nuclei)'\n",
      "'2D_versatile_he'     'Versatile (H&E nuclei)'\n",
      "'2D_paper_dsb2018'    'DSB 2018 (from StarDist 2D paper)'\n",
      "'2D_demo'             None\n",
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n"
     ]
    }
   ],
   "source": [
    "model_weights_path = 'weights_best_42stacks_all.h5'\n",
    "model, model_2D = load_model_3D_and_2D(model_weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a976324-6b99-47c1-95c5-46921636535f",
   "metadata": {},
   "source": [
    "- specify the dataset path, channel, saved folder\n",
    "- the data.h5 store [frame, channel, depth, width, heighth]\n",
    "- obtain the raw segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "77633573-3118-44f7-9fcc-7c6e3ac15533",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path('/work/venkatachalamlab/Hang/00Identify_neuron/datasets/sexual_dimorphism_frame/male/20220329_male_10_processed')\n",
    "ch = 1 ## specify the channel to segmentation\n",
    "zoom_factor = 2 ## microfluid/NeuroPAL use 1, behaving worms use 2 if shape is (23,512,512) \n",
    "seg_path = dataset_path/'seg' ## saved folder\n",
    "seg_path.mkdir(parents=True, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "t_idx = 0 ## select which frame\n",
    "gamma = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa407e31-0b58-4556-9524-7fe21fbbf5e0",
   "metadata": {},
   "source": [
    "## hey Sina, this is the raw segmentation from the trained 3D stardist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e6a1d77-365c-42aa-b46b-1e44249a4dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_z = get_frame_segmentation(model,model_2D,t_idx, ch, zoom_factor,dataset_path,gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6efb2dfc-4a34-4971-875f-96ae9a61ba37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(label_z).shape ## the number of found neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d83fb0b-0e7b-4e23-8460-7ac59b06b391",
   "metadata": {},
   "source": [
    "### - save the segmented data into h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bd142288-6bad-48ca-875d-02f9c41dfd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_var_h5(seg_path / (str(t_idx)+'.h5') ,[label_z],['label'])\n",
    "# print(\"finish the segmentation of movie in the folder path: \", folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fe12b8-ed7e-441c-b669-05c396a507f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e0e168-4cd7-4839-add6-5318a3d3b971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc124d24-6f55-45b6-9c47-fb00cd827acb",
   "metadata": {},
   "source": [
    "- extract the centroid from the segmentation\n",
    "- use these centroid to group the 2D segmented nuclei\n",
    "- apply watershed algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9bc1fb48-2306-417a-b336-52ff86148de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  14.          216.96842105 1016.44210526]\n",
      " [  10.29411765  191.875       492.91911765]\n",
      " [  13.44047619  425.11904762  929.45238095]\n",
      " ...\n",
      " [   9.19205298  420.39735099  474.60927152]\n",
      " [  17.07042254  147.92957746  595.85915493]\n",
      " [  14.45517241  502.58965517  743.83793103]]\n"
     ]
    }
   ],
   "source": [
    "from skimage.measure import regionprops\n",
    "\n",
    "props = regionprops(label_z)\n",
    "centroids = np.array([prop.centroid for prop in props])\n",
    "print(centroids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d90ebab6-796e-42ae-b58f-5b20a0bbf247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d07baa41-cab8-48b4-8eeb-6c869b99b99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_func import *\n",
    "from Seg_pos import *\n",
    "\n",
    "## specify the parameters\n",
    "isotropy_scale  = (5,1,1)\n",
    "normalize_lim = (3,99.5) #(1,99.5)\n",
    "zoom_factor = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e353ef36-9e79-4ef1-9f74-d832be0c133a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353,)\n"
     ]
    }
   ],
   "source": [
    "img_original, _ = get_volume_at_frame(dataset_path/'data.h5',t_idx)\n",
    "abs_pos = np.round(centroids).astype(np.int16)\n",
    "gray_volume = img_original[0,ch]\n",
    "apply_NucleiSegmentation = NucleiSegmentationAnnotation_test(gray_volume, model_2D, isotropy_scale,  normalize_lim, zoom_factor)\n",
    "seg = apply_NucleiSegmentation.run_segmentation(abs_pos)\n",
    "print(np.unique(seg).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4cecd5-e225-4e48-9a9e-db5144397830",
   "metadata": {},
   "source": [
    "## Hey Sina,the 'seg' is the refined segmentation \n",
    "Happy to hear from you about any questions and let me know if any of issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ca711b-1cb9-4d30-98ce-11fc22961721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fe4506-7111-4614-854a-36be340abf36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d253d7d2-6ab9-4fcf-8697-df8af3fa19b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072f95d3-556a-4b5f-99d4-ec1b8b20e1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2edbd0-4f45-4645-848f-ba8b93b76d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db95dd54-21ab-4243-b4a5-999dab62db12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabde9fa-dc29-4fbc-8272-ce66d8f7a1a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c6be0adb-715d-4da4-a47e-443fe8b33a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load annotations \n",
    "# import pandas as pd\n",
    "# with h5py.File(dataset_path / 'annotations.h5', 'r') as f:\n",
    "#     data = {key: f[key][:] for key in f.keys()}\n",
    "    \n",
    "# df = pd.DataFrame(data)\n",
    "# df = df[df['t_idx']==t_idx]\n",
    "# img_shape = np.array(label_z.shape)\n",
    "# pos = df[['z','y','x']].values * (img_shape-1)\n",
    "# pos = np.round(pos).astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94391cbe-cd85-4ed7-9124-74785cecd94a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
